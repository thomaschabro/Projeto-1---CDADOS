{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Matheus Souza\n",
    "\n",
    "Nome: Pedro Ivo\n",
    "\n",
    "Nome: Thomas Chabro"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "%matplotlib inline\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "\r\n",
    "# Para a separa√ß√£o de emojis e palavras:\r\n",
    "!pip install emoji\r\n",
    "\r\n",
    "import functools\r\n",
    "import operator\r\n",
    "import re\r\n",
    "import emoji"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: emoji in c:\\anaconda\\lib\\site-packages (1.5.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "c:\\Users\\Lieselotte Chabro\\Desktop\\Insper\\Arquivos VS CODE\\Biblioteca\\2¬∫ Semestre\\CDADOS\\Projeto 1 final\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "filename = 'certified lover boy 2.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mas ent√£o quer dizer que o drake foi mais um a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üîä atualiza√ß√µes spotify: \\n\\n‚Ä¢ drake teve a mel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>certified lover boy vai ser agora</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>come√ßando a ouvir s√≥ agora o novo √°lbum do dra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hmmmm, como assim todos s√£o certified lover bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>obrigado drake por ter lan√ßado essa fucking ob...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>meu album: certified lover boy \\nm√∫sica favori...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>nem donda, nem certified lover boy. da√≠ a cesa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>o √°lbum ‚Äúcertified lover boy‚Äù, de drake, se to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>o drake n√£o lan√ßa nada de bom desde 2015, n√©\\n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relev√¢ncia\n",
       "0    mas ent√£o quer dizer que o drake foi mais um a...           1\n",
       "1    üîä atualiza√ß√µes spotify: \\n\\n‚Ä¢ drake teve a mel...           0\n",
       "2                    certified lover boy vai ser agora           1\n",
       "3    come√ßando a ouvir s√≥ agora o novo √°lbum do dra...           1\n",
       "4    hmmmm, como assim todos s√£o certified lover bo...           1\n",
       "..                                                 ...         ...\n",
       "545  obrigado drake por ter lan√ßado essa fucking ob...           3\n",
       "546  meu album: certified lover boy \\nm√∫sica favori...           3\n",
       "547  nem donda, nem certified lover boy. da√≠ a cesa...           2\n",
       "548  o √°lbum ‚Äúcertified lover boy‚Äù, de drake, se to...           0\n",
       "549  o drake n√£o lan√ßa nada de bom desde 2015, n√©\\n...           3\n",
       "\n",
       "[550 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oq falar de certified lover boy? puta √°lbum do...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>certified lover boy √© bom, hein?!</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a qualidade de donda √© inversamente proporcion...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'certified lover boy' foi para o primeiro luga...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>creditado em donda e certified lover boy https...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>dei uma aten√ß√£o maior pro certified lover boy ...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ouvindo o certified lover boy</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>donda e certified lover boy üõêüõê os cara erra nunca</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>o j.cole j√° dropou \"the off season\"\\no young t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>certified lover boy??? o lil nas x que me d√™ o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relev√¢ncia  \\\n",
       "0    oq falar de certified lover boy? puta √°lbum do...           3   \n",
       "1                    certified lover boy √© bom, hein?!           3   \n",
       "2    a qualidade de donda √© inversamente proporcion...           2   \n",
       "3    'certified lover boy' foi para o primeiro luga...           0   \n",
       "4    creditado em donda e certified lover boy https...           1   \n",
       "..                                                 ...         ...   \n",
       "195  dei uma aten√ß√£o maior pro certified lover boy ...           3   \n",
       "196                      ouvindo o certified lover boy           1   \n",
       "197  donda e certified lover boy üõêüõê os cara erra nunca           3   \n",
       "198  o j.cole j√° dropou \"the off season\"\\no young t...           0   \n",
       "199  certified lover boy??? o lil nas x que me d√™ o...           0   \n",
       "\n",
       "     Classificador  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "..             ...  \n",
       "195            NaN  \n",
       "196            NaN  \n",
       "197            NaN  \n",
       "198            NaN  \n",
       "199            NaN  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para a classifica√ß√£o dos tweets, foram criadas quatro categorias:\r\n",
    "\r\n",
    "**0 - NEUTRO**: Indica not√≠cias\r\n",
    "\r\n",
    "**1 - IRRELEVANTE**: Tweets realmente irrelevantes\r\n",
    "\r\n",
    "**2 - RELEVANTE**: Ligado √† compara√ß√£o, como ocorreu frequentemente, comparando o √°lbum (nosso tema) com outros √°lbuns \r\n",
    "\r\n",
    "**3 - MUITO RELEVANTE**: Tweets que apresentem opini√µes expl√≠citas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dados = pd.read_excel('certified lover boy 2.xlsx')\r\n",
    "dados['Relev√¢ncia'].value_counts(True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3    0.296364\n",
       "1    0.287273\n",
       "2    0.227273\n",
       "0    0.189091\n",
       "Name: Relev√¢ncia, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dados_treinamento = pd.read_excel('certified lover boy 2.xlsx', 'Treinamento')\r\n",
    "dados_teste = pd.read_excel('certified lover boy 2.xlsx', 'Teste')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "'''\r\n",
    "Fun√ß√£o para separa√ß√£o de emojis e palavras\r\n",
    "\r\n",
    "Esta fun√ß√£o receber√° uma string (no caso um texto), e retornar√° uma lista com todas as palavras e emojis separados\r\n",
    "'''\r\n",
    "\r\n",
    "def separador(text):\r\n",
    "    em = text\r\n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(em)\r\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\r\n",
    "    em_split = functools.reduce(operator.concat, em_split_whitespace)\r\n",
    "    return em_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "list_special_characterers = ['@', '\\n', ',', '\"', '(', ')', '/', '*', '>', '<', '.', ':']\r\n",
    "\r\n",
    "for index in dados_treinamento.index:\r\n",
    "    new_text = ''\r\n",
    "    for character in dados_treinamento.loc[index, 'Treinamento']:\r\n",
    "        if character not in list_special_characterers:\r\n",
    "            new_text += character\r\n",
    "            dados_treinamento.loc[index, 'Treinamento'] = new_text\r\n",
    "\r\n",
    "dados_treinamento"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mas ent√£o quer dizer que o drake foi mais um a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üîä atualiza√ß√µes spotify ‚Ä¢ drake teve a melhor e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>certified lover boy vai ser agora</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>come√ßando a ouvir s√≥ agora o novo √°lbum do dra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hmmmm como assim todos s√£o certified lover boy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>obrigado drake por ter lan√ßado essa fucking ob...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>meu album certified lover boy m√∫sica favorita ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>nem donda nem certified lover boy da√≠ a cesar ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>o √°lbum ‚Äúcertified lover boy‚Äù de drake se torn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>o drake n√£o lan√ßa nada de bom desde 2015 n√©ess...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relev√¢ncia\n",
       "0    mas ent√£o quer dizer que o drake foi mais um a...           1\n",
       "1    üîä atualiza√ß√µes spotify ‚Ä¢ drake teve a melhor e...           0\n",
       "2                    certified lover boy vai ser agora           1\n",
       "3    come√ßando a ouvir s√≥ agora o novo √°lbum do dra...           1\n",
       "4    hmmmm como assim todos s√£o certified lover boy...           1\n",
       "..                                                 ...         ...\n",
       "545  obrigado drake por ter lan√ßado essa fucking ob...           3\n",
       "546  meu album certified lover boy m√∫sica favorita ...           3\n",
       "547  nem donda nem certified lover boy da√≠ a cesar ...           2\n",
       "548  o √°lbum ‚Äúcertified lover boy‚Äù de drake se torn...           0\n",
       "549  o drake n√£o lan√ßa nada de bom desde 2015 n√©ess...           3\n",
       "\n",
       "[550 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "read = ''\r\n",
    "\r\n",
    "for index in dados_treinamento.index:\r\n",
    "    for character in dados_treinamento.loc[index, 'Treinamento']:\r\n",
    "        read += character\r\n",
    "        \r\n",
    "todas_as_palavras_treinamento = read.split()\r\n",
    "\r\n",
    "series_treinamento = pd.Series(todas_as_palavras_treinamento)\r\n",
    "\r\n",
    "series_treinamento.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "lover             546\n",
       "certified         429\n",
       "boy               408\n",
       "o                 297\n",
       "de                259\n",
       "                 ... \n",
       "sensocertified      1\n",
       "fuck                1\n",
       "comidas             1\n",
       "m√°ximoal√¥           1\n",
       "posso               1\n",
       "Length: 2559, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dados_treinamento['Relev√¢ncia'] = dados_treinamento.Relev√¢ncia.astype('category')\r\n",
    "dados_treinamento.Relev√¢ncia.cat.categories = ['Neutro', 'Irrelevante', 'Relevante', 'Muito relevante']\r\n",
    "dados_treinamento.Relev√¢ncia.cat.categories\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "dados_teste['Relev√¢ncia'] = dados_teste.Relev√¢ncia.astype('category')\r\n",
    "dados_teste.Relev√¢ncia.cat.categories = ['Neutro', 'Irrelevante', 'Relevante', 'Muito relevante']\r\n",
    "dados_teste.Relev√¢ncia.cat.categories\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Neutro', 'Irrelevante', 'Relevante', 'Muito relevante'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "dados_treinamento_neutro = dados_treinamento.loc[dados_treinamento['Relev√¢ncia'] == 'Neutro', :]\r\n",
    "dados_treinamento_irrelevante = dados_treinamento.loc[dados_treinamento.Relev√¢ncia == 'Irrelevante', :]\r\n",
    "dados_treinamento_relevante = dados_treinamento.loc[dados_treinamento.Relev√¢ncia == 'Relevante', :]\r\n",
    "dados_treinamento_mt_relevante = dados_treinamento.loc[dados_treinamento.Relev√¢ncia == 'Muito relevante', :]\r\n",
    "\r\n",
    "#---------------------------------------------------------------------------------------------    \r\n",
    "\r\n",
    "read_neutro = ''\r\n",
    "\r\n",
    "for index in dados_treinamento_neutro.index:\r\n",
    "    for character in dados_treinamento_neutro.loc[index, 'Treinamento']:\r\n",
    "        read_neutro += character\r\n",
    "    read_neutro += ' '\r\n",
    "\r\n",
    "todas_as_palavras_treinamento_neutro = separador(read_neutro)\r\n",
    "series_treinamento_neutro = pd.Series(todas_as_palavras_treinamento_neutro)\r\n",
    "        \r\n",
    "#---------------------------------------------------------------------------------------------    \r\n",
    "    \r\n",
    "read_irrelevante = ''\r\n",
    "\r\n",
    "for index in dados_treinamento_irrelevante.index:\r\n",
    "    for character in dados_treinamento_irrelevante.loc[index, 'Treinamento']:\r\n",
    "        read_irrelevante += character\r\n",
    "    read_irrelevante += ' '\r\n",
    "        \r\n",
    "todas_as_palavras_treinamento_irrelevante = separador(read_irrelevante)\r\n",
    "series_treinamento_irrelevante = pd.Series(todas_as_palavras_treinamento_irrelevante)\r\n",
    "\r\n",
    "#---------------------------------------------------------------------------------------------    \r\n",
    "\r\n",
    "read_relevante = ''\r\n",
    "\r\n",
    "for index in dados_treinamento_relevante.index:\r\n",
    "    for character in dados_treinamento_relevante.loc[index, 'Treinamento']:\r\n",
    "        read_relevante += character\r\n",
    "    read_relevante += ' ' \r\n",
    "        \r\n",
    "todas_as_palavras_treinamento_relevante = separador(read_relevante)\r\n",
    "series_treinamento_relevante = pd.Series(todas_as_palavras_treinamento_relevante)         \r\n",
    "\r\n",
    "#---------------------------------------------------------------------------------------------    \r\n",
    "\r\n",
    "read_mt_relevante = ''\r\n",
    "\r\n",
    "for index in dados_treinamento_mt_relevante.index:\r\n",
    "    for character in dados_treinamento_mt_relevante.loc[index, 'Treinamento']:\r\n",
    "        read_mt_relevante += character\r\n",
    "    read_mt_relevante += ' '\r\n",
    "\r\n",
    "todas_as_palavras_treinamento_mt_relevante = separador(read_mt_relevante)\r\n",
    "series_treinamento_mt_relevante = pd.Series(todas_as_palavras_treinamento_mt_relevante)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Criando tabelas com a contagem das palavras\r\n",
    "\r\n",
    "tabela_neutro = series_treinamento_neutro.value_counts()\r\n",
    "tabela_irrelevante = series_treinamento_irrelevante.value_counts()\r\n",
    "tabela_relevante = series_treinamento_relevante.value_counts()\r\n",
    "tabela_mt_relevante = series_treinamento_mt_relevante.value_counts()\r\n",
    "\r\n",
    "# Criando ent√£o as tabelas relativas, com a contagem relativa das palavras\r\n",
    "\r\n",
    "tabela_neutro_relativa  = series_treinamento_neutro.value_counts(True)\r\n",
    "tabela_irrelevante_relativa  = series_treinamento_irrelevante.value_counts(True)\r\n",
    "tabela_relevante_relativa  = series_treinamento_relevante.value_counts(True)\r\n",
    "tabela_mt_relevante_relativa  = series_treinamento_mt_relevante.value_counts(True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "tabela_neutro_relativa"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "de           0.041801\n",
       "lover        0.040997\n",
       "o            0.030949\n",
       "certified    0.029743\n",
       "boy          0.028537\n",
       "               ...   \n",
       "iii          0.000402\n",
       "samples      0.000402\n",
       "durante      0.000402\n",
       "pq           0.000402\n",
       "cada         0.000402\n",
       "Length: 920, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "tabela_irrelevante_relativa"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "lover        0.075362\n",
       "certified    0.072947\n",
       "boy          0.068599\n",
       "o            0.029952\n",
       "e            0.020290\n",
       "               ...   \n",
       "ü§∞üèª           0.000483\n",
       "apoiando     0.000483\n",
       "d√∫vidas      0.000483\n",
       "concretas    0.000483\n",
       "vcs          0.000483\n",
       "Length: 771, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "tabela_relevante_relativa"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "lover        0.049104\n",
       "certified    0.047935\n",
       "boy          0.045596\n",
       "donda        0.037023\n",
       "o            0.033905\n",
       "               ...   \n",
       "concorda     0.000390\n",
       "alezudoo     0.000390\n",
       "thru         0.000390\n",
       "ent√£o        0.000390\n",
       "obg          0.000390\n",
       "Length: 831, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "tabela_mt_relevante_relativa"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "lover        0.059316\n",
       "certified    0.058952\n",
       "boy          0.055677\n",
       "o            0.033843\n",
       "de           0.027293\n",
       "               ...   \n",
       "foda         0.000364\n",
       "mixtape      0.000364\n",
       "ü§§            0.000364\n",
       "mid          0.000364\n",
       "tocando      0.000364\n",
       "Length: 825, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Definindo as probabilidades de cada relev√¢ncia\r\n",
    "\r\n",
    "todas_as_palavras_treinamento = read_neutro + read_irrelevante + read_relevante + read_mt_relevante\r\n",
    "todas_as_palavras_treinamento = todas_as_palavras_treinamento.split()\r\n",
    "\r\n",
    "P_Neutro = len(todas_as_palavras_treinamento_neutro)/len(todas_as_palavras_treinamento)\r\n",
    "P_Irrelevante = len(todas_as_palavras_treinamento_irrelevante)/len(todas_as_palavras_treinamento)\r\n",
    "P_Relevante = len(todas_as_palavras_treinamento_relevante)/len(todas_as_palavras_treinamento)\r\n",
    "P_Muito_Revelevante = len(todas_as_palavras_treinamento_mt_relevante)/len(todas_as_palavras_treinamento)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "P_Neutro"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.25382574984697"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "P_Irrelevante"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.21118139155274435"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "P_Relevante"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.26178330952866763"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "P_Muito_Revelevante"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.28035094878596206"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Definindo fun√ß√£o para limpar a frase, removendo caracteres especiais\r\n",
    "\r\n",
    "def cleanup (frase):\r\n",
    "    saida = ''\r\n",
    "    for el in frase:\r\n",
    "        if el not in list_special_characterers:\r\n",
    "            saida += el\r\n",
    "    return saida\r\n",
    "\r\n",
    "def classificador (frase):\r\n",
    "\r\n",
    "    frase = cleanup(frase.lower())\r\n",
    "    lista_frase = separador(frase)\r\n",
    "    \r\n",
    "    # Calculando probabilidades\r\n",
    "\r\n",
    "    Prob_ser_neutro = 1\r\n",
    "    for palavra in lista_frase:\r\n",
    "        if palavra not in tabela_neutro:\r\n",
    "            x = 0\r\n",
    "        else:\r\n",
    "            x = tabela_neutro[palavra]\r\n",
    "        p_palavra = (x + 1)/(len(tabela_neutro) + len(todas_as_palavras_treinamento))\r\n",
    "        Prob_ser_neutro *= p_palavra\r\n",
    "    Prob_ser_neutro *= P_Neutro\r\n",
    "\r\n",
    "    Prob_ser_irrelevante = 1\r\n",
    "    for el in lista_frase:\r\n",
    "        if el not in tabela_irrelevante:\r\n",
    "            x = 0\r\n",
    "        else:\r\n",
    "            x = tabela_irrelevante[el]\r\n",
    "        p_el = (x + 1)/(len(tabela_irrelevante) + len(todas_as_palavras_treinamento))\r\n",
    "        Prob_ser_irrelevante *= p_el\r\n",
    "    Prob_ser_irrelevante *= P_Irrelevante\r\n",
    "\r\n",
    "    Prob_ser_relevante = 1\r\n",
    "    for el in lista_frase:\r\n",
    "        if el not in tabela_relevante:\r\n",
    "            x = 0\r\n",
    "        else:\r\n",
    "            x = tabela_relevante[el]\r\n",
    "        p_el = (x + 1)/(len(tabela_relevante) + len(todas_as_palavras_treinamento))\r\n",
    "        Prob_ser_relevante *= p_el\r\n",
    "    Prob_ser_relevante *= P_Relevante\r\n",
    "\r\n",
    "    Prob_ser_mt_relevante = 1\r\n",
    "    for el in lista_frase:\r\n",
    "        if el not in tabela_mt_relevante:\r\n",
    "            x = 0\r\n",
    "        else:\r\n",
    "            x = tabela_mt_relevante[el]\r\n",
    "        p_el = (x + 1)/(len(tabela_mt_relevante) + len(todas_as_palavras_treinamento))\r\n",
    "        Prob_ser_mt_relevante *= p_el\r\n",
    "    Prob_ser_mt_relevante *= P_Muito_Revelevante\r\n",
    "\r\n",
    "    lista_probabilidades = [Prob_ser_neutro, Prob_ser_irrelevante, Prob_ser_relevante, Prob_ser_mt_relevante]\r\n",
    "    i = lista_probabilidades.index(max(lista_probabilidades))\r\n",
    "    if i == 0:\r\n",
    "        return ('Neutro')\r\n",
    "    if i == 1:\r\n",
    "        return ('Irrelevante')\r\n",
    "    if i == 2:\r\n",
    "        return ('Relevante')\r\n",
    "    if i == 3:\r\n",
    "        return ('Muito relevante')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "i = 0\r\n",
    "for frase in dados_teste['Teste']:\r\n",
    "    rate = classificador(frase)\r\n",
    "    dados_teste.loc[i, 'Classificador'] = rate\r\n",
    "    i += 1\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "dados_teste['Relev√¢ncia'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Muito relevante    63\n",
       "Neutro             56\n",
       "Relevante          46\n",
       "Irrelevante        35\n",
       "Name: Relev√¢ncia, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "falso_mt_relevante = 0\r\n",
    "verdadeiro_mt_relevante = 0\r\n",
    "falso_relevante = 0\r\n",
    "verdadeiro_relevante = 0\r\n",
    "falso_irrelevante = 0\r\n",
    "verdadeiro_irrelevante = 0\r\n",
    "falso_neutro = 0\r\n",
    "verdadeiro_neutro = 0\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "for index in dados_teste.index:\r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] == 'Muito relevante' and dados_teste.loc[index, 'Classificador'] == 'Muito relevante':\r\n",
    "        verdadeiro_mt_relevante += 1\r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] != 'Muito relevante' and dados_teste.loc[index, 'Classificador'] == 'Muito relevante':\r\n",
    "        falso_mt_relevante += 1\r\n",
    "    \r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] == 'Relevante' and dados_teste.loc[index, 'Classificador'] == 'Relevante':\r\n",
    "        verdadeiro_relevante += 1\r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] != 'Relevante' and dados_teste.loc[index, 'Classificador'] == 'Relevante':\r\n",
    "        falso_relevante += 1\r\n",
    "    \r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] == 'Irrelevante' and dados_teste.loc[index, 'Classificador'] == 'Irrelevante':\r\n",
    "        verdadeiro_irrelevante += 1\r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] != 'Irrelevante' and dados_teste.loc[index, 'Classificador'] == 'Irrelevante':\r\n",
    "        falso_irrelevante += 1\r\n",
    "        \r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] == 'Neutro' and dados_teste.loc[index, 'Classificador'] == 'Neutro':\r\n",
    "        verdadeiro_neutro += 1\r\n",
    "    if dados_teste.loc[index, 'Relev√¢ncia'] != 'Neutro' and dados_teste.loc[index, 'Classificador'] == 'Neutro':\r\n",
    "        falso_neutro += 1\r\n",
    "    \r\n",
    "    \r\n",
    "print(f'Porcentagem de verdadeiros muito relevantes: {verdadeiro_mt_relevante/(verdadeiro_mt_relevante + falso_mt_relevante)}')\r\n",
    "print(f'Porcentagem de falsos muito relevantes: {falso_mt_relevante/(verdadeiro_mt_relevante + falso_mt_relevante)}')\r\n",
    "print('\\n')\r\n",
    "print(f'Porcentagem de verdadeiros relevantes: {verdadeiro_relevante/(verdadeiro_relevante + falso_relevante)}')\r\n",
    "print(f'Porcentagem de falsos relevantes: {falso_relevante/(verdadeiro_relevante + falso_relevante)}')\r\n",
    "print('\\n')\r\n",
    "print(f'Porcentagem de verdadeiros irrelevantes: {verdadeiro_irrelevante/(verdadeiro_irrelevante + falso_irrelevante)}')\r\n",
    "print(f'Porcentagem de falsos irrelevantes: {falso_irrelevante/(verdadeiro_irrelevante + falso_irrelevante)}')\r\n",
    "print('\\n')\r\n",
    "print(f'Porcentagem de verdadeiros neutros: {verdadeiro_neutro/(verdadeiro_neutro + falso_neutro)}')\r\n",
    "print(f'Porcentagem de falsos neutros: {falso_neutro/(verdadeiro_neutro + falso_neutro)}')\r\n",
    "\r\n",
    "   \r\n",
    "# Acur√°cia\r\n",
    "acuracia = 0\r\n",
    "total = 0\r\n",
    "for i in dados_teste.index:\r\n",
    "    if dados_teste.loc[i, 'Relev√¢ncia'] == dados_teste.loc[i, 'Classificador']:\r\n",
    "        acuracia += 1\r\n",
    "    total += 1\r\n",
    "\r\n",
    "acuracia = (acuracia/total) * 100\r\n",
    "print('\\n')\r\n",
    "print(f'Porcentagem de acertos do Classificador (acur√°cia): {acuracia}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Porcentagem de verdadeiros muito relevantes: 0.5217391304347826\n",
      "Porcentagem de falsos muito relevantes: 0.4782608695652174\n",
      "\n",
      "\n",
      "Porcentagem de verdadeiros relevantes: 0.5070422535211268\n",
      "Porcentagem de falsos relevantes: 0.49295774647887325\n",
      "\n",
      "\n",
      "Porcentagem de verdadeiros irrelevantes: 0.3\n",
      "Porcentagem de falsos irrelevantes: 0.7\n",
      "\n",
      "\n",
      "Porcentagem de verdadeiros neutros: 0.8518518518518519\n",
      "Porcentagem de falsos neutros: 0.14814814814814814\n",
      "\n",
      "\n",
      "Porcentagem de acertos do Classificador (acur√°cia): 55.00000000000001\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "\r\n",
    "# Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Performance do Classificador**\r\n",
    "\r\n",
    "Para a an√°lise cr√≠tica do classificador, foram feitos c√°lculos acerca de sua performance, que dar√£o embasamento para obter uma conclus√£o mais aprofundada e concreta. Entre estes c√°lculos, est√£o o c√°lculo da porcentagem de verdades e falsos de cada categoria, assim como a acur√°cia total do Classificador.\r\n",
    "\r\n",
    "A partir da porcentagem de acertos, de aproximadamente 55%, nota-se que existe uma margem razoavelmente boa de acertos, beirando os 60%, mas ainda assim longe de um patamar considerado como elevado. Entretanto, analisar apenas este dado n√£o nos d√° um panomarama realmente completo, pois se trata de uma informa√ß√£o muito geral.\r\n",
    "\r\n",
    "Dessa forma, para uma an√°lise mais espec√≠fica e, consequentemente, mais aprofundada, foram feitos os c√°lculos da porcetagem de verdadeiros e falsos de cada categoria. \r\n",
    "\r\n",
    "Analisando estes dados, nota-se que quase todas as categorias obtiveram pelo menos, aproximadamente, 50% de acertos. Podemos ainda dar √™nfase para a categoria 'Muito Relevante', que se distanciou dos demais com uma porcentagem de verdadeiros de 82%. Isto pode ocorrer talvez pelo fato de a categoria 'Muito Relevante' possuir palavras mais \"√∫nicas\", mais espec√≠ficas da categoria. \r\n",
    "\r\n",
    "Por outro lado, pode-se entender estes n√∫meros como um exagero por parte do Classificador, de classificar muitos tweets nesta √∫ltima categoria, aumentando consequentemente o n√∫mero de verdadeiros dela. Esta ideia, por sua vez, era algo esperado, dado que a categoria 'Muito Relevante' diz respeito √† opini√µes, que s√£o a maioria quando falamos de twitter. \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Outras aplica√ß√µes para o classificador Naive Bayes**\r\n",
    "\r\n",
    "O classificador Naive Bayes pode ser facilmente aplicado, dado que √© relativamente r√°pido e necessita de poucos dados para funcionar.Dado isso, ele pode ser utilizado para diversas outras fun√ß√µes de classifica√ß√£o, incluindo previs√µes em tempo real.\r\n",
    "\r\n",
    "Al√©m da classifica√ß√£o de texto, utilizada nesse Projeto, podemos tamb√©m aplicar, por exemplo, para a filtragem de SPAM, em e-mails. Com uma base de dados, √© poss√≠vel classificar quais e-mails s√£o propaganda, canais de venda e outras mensagens indesej√°veis. \r\n",
    "\r\n",
    "Outro exemplo muito √∫til, seria o diagn√≥stico m√©dico autom√°tico. A partir de uma base de dados de sintomas e doen√ßas, o classificador poderia receber os sintomas do paciente e dizer qual doen√ßa ele possui."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Por que n√£o utilizar o classificador para gerar mais amostras de treinamento?**\r\n",
    "\r\n",
    "Explicou porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento: O classificador n√£o √© uma intelig√™ncia artificial perfeita, logo ele classifica alguns tweets com a relev√¢ncia errada. Dessa forma, se us√°ssemos os tweets do classificador como base de treinamento, o nosso naive bayes treinaria (tomando como verdade) com alguns falsos positivos e falsos negativos, alterando totalmente a classifica√ß√£o dos proximos tweets a serem testados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "\r\n",
    "# Sugest√µes de Aperfei√ßoamento\r\n",
    "\r\n",
    "**1. Utilizar probabilidas com log**\r\n",
    "\r\n",
    "Umas das possibilidades de melhora do classificador, √© trabalhar com as possibilidades em log. Para evitar trabalhar com n√∫meros muito pequenos, podemos usar o logar√≠timo dos valores das probabilidades. \r\n",
    "A fun√ß√£o de log mapeia os valores de probabilidade do intervalo [0, 1], fazendo com que os valores das probabilidade do log sejam negativos. Dessa forma, quanto menor for o valor do logar√≠timo, ele ser√° mapeado para um valor maior negativo pela fun√ß√£o de log.\r\n",
    "\r\n",
    "Assim, para aplicar, dever√≠amos utilizar a equa√ß√£o:\r\n",
    "\r\n",
    "<p><img src='https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-6beadb40c93de8340c1b656900e6b548_l3.svg' alt='equacao_img'></p>\r\n",
    "\r\n",
    "Refer√™ncia: <https://www.baeldung.com/cs/naive-bayes-classification-performance>\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Elimina√ß√£o de \"stopwords**\r\n",
    "\r\n",
    "Stopwords s√£o palavras que n√£o necessariamente ajudam na constru√ß√£o e treinamento do classificador. Artigos como 'a' e 'o', ou outras palavras gen√©ricas podem ser removidas, a fim de obter apenas as \"palavras chave\" do texto. Uma frase como 'O novo √°lbum do draka √© ruim', seria reduzida apenas √† 'novo √°lbum drake ruim', ajudando o classificador por eliminar palavras sem uma real import√¢ncia.\r\n",
    "\r\n",
    "Para aplicar este m√©todo, deveria ser criada uma lista com as palavras a serem eliminadas. Tendo esta lista, seriam rodadas todas as palavras do treinamento, e ent√£o removidas as pertencentes √† lista.\r\n",
    "\r\n",
    "Entretanto, este processo pode n√£o ser necessariamente ben√©fico ao classificador. Isto pois o uso de artigos e outras palavras pode ser caracter√≠stico de frases mais bem elaboradas, o que ajudaria o classificador √† diferenciar uma frase desse tipo de outras mais simples.\r\n",
    "\r\n",
    "Refer√™ncia: <https://en.wikipedia.org/wiki/Stop_word>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Lematiza√ß√£o de palavras**\r\n",
    "\r\n",
    "Fazer o agrupamento de diferentes palavras derivadas de uma mesma palavra, para que obtenham a mesma classifica√ß√£o, aperfei√ßoando o classificador.\r\n",
    "\r\n",
    "**4. Uso n-gramas**\r\n",
    "\r\n",
    "Ao inv√©s de contar palavras √∫nicas, este m√©todo faz uma contagem de uma sequ√™ncia de palavras espec√≠ficas de sua prefer√™ncia, a qual ter√° uma certa classifica√ß√£o.\r\n",
    "\r\n",
    "**5. Uso de TF-IDF**\r\n",
    "\r\n",
    "Fazer uma penaliza√ß√£o para as palavras mais frequentes do dataframe. No caso desse projeto, seriam as palavras chave do tweet(No nosso, pode ser certified, lover e boy), as quais aparecem obrigatoriamente nos tweets. Isso faria com que a relev√¢ncia delas n√£o fosse considerada, melhorando a qualidade do classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Aperfei√ßoamento:\r\n",
    "\r\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\r\n",
    "\r\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\r\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\r\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\r\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\r\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\r\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\r\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Refer√™ncias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}